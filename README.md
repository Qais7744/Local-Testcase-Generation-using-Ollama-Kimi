# ğŸ§ª Local Test Case Generator

> **AI-Powered Test Case Generation using Local LLMs (Ollama + Llama 3.2)**

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Flask](https://img.shields.io/badge/Flask-2.3+-green.svg)](https://flask.palletsprojects.com)
[![Ollama](https://img.shields.io/badge/Ollama-Local%20AI-orange.svg)](https://ollama.com)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

Generate comprehensive test cases from Python code or feature descriptions **without sending data to external APIs**. Your code stays private and secure! ğŸ”’

<p align="center">
  <img src="https://img.shields.io/badge/Manual%20Test%20Cases-âœ“-brightgreen" alt="Manual Test Cases">
  <img src="https://img.shields.io/badge/pytest%20Automation-âœ“-blue" alt="pytest Automation">
  <img src="https://img.shields.io/badge/100%25%20Local-âœ“-purple" alt="100% Local">
</p>

---

## ğŸ“‹ Table of Contents

- [âœ¨ Features](#-features)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ“¦ Installation](#-installation)
- [â–¶ï¸ Usage](#-usage)
- [ğŸ—ï¸ System Architecture](#ï¸-system-architecture)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ”§ Configuration](#-configuration)
- [ğŸ› Troubleshooting](#-troubleshooting)
- [ğŸ“„ License](#-license)

---

## âœ¨ Features

### ğŸ¯ Core Capabilities

| Feature | Input | Output | Speed |
|---------|-------|--------|-------|
| **ğŸ Python Code Testing** | `def add(a, b): return a+b` | Manual + pytest | âš¡ Instant |
| **ğŸ“ Feature Testing** | "Login with email, password" | Test scenarios | âš¡ Instant |
| **ğŸŒ Website Testing** | "google.com" | UI test cases | âš¡ Instant |
| **ğŸ”’ 100% Private** | Local processing | No cloud | ğŸ›¡ï¸ Secure |

---

## ğŸš€ Quick Start

### One-Command Start (Windows)
```powershell
cd Project1-LocalTestCaseGenerator
.\START.bat
```

### Manual Start
```powershell
# Terminal 1 - Start Ollama
ollama serve

# Terminal 2 - Start Web Server
cd Project1-LocalTestCaseGenerator
python deploy.py
```

### Access the App
Open browser: **http://localhost:5000**

---

## ğŸ“¦ Installation

### Prerequisites

| Requirement | Version | Install Command |
|------------|---------|-----------------|
| Python | 3.8+ | [Download](https://python.org/downloads) |
| Ollama | Latest | [Download](https://ollama.com/download) |
| Llama 3.2 | latest | `ollama pull llama3.2` |

### Step-by-Step Setup

```powershell
# 1. Clone the repository
git clone https://github.com/Qais7744/Local-Testcase-Generation-using-Ollama-Kimi.git
cd Local-Testcase-Generation-using-Ollama-Kimi

# 2. Navigate to project
cd Project1-LocalTestCaseGenerator

# 3. Install Python dependencies
pip install -r requirements.txt

# 4. Pull the LLM model (one-time)
ollama pull llama3.2

# 5. Start the application
.\START.bat
```

---

## â–¶ï¸ Usage

### ğŸŒ Web Interface

1. **Open** http://localhost:5000 in your browser
2. **Select Input Type:**
   - ğŸ **Python Code** - Paste function/class code
   - ğŸ“ **Feature Description** - Write plain text requirements
   - ğŸŒ **Website URL** - Enter domain (e.g., `google.com`)
3. **Click** "Generate" or press `Ctrl + Enter`
4. **View Results:**
   - ğŸ“‹ Manual Test Cases (TC_001, TC_002...)
   - ğŸ§ª pytest Automation Code

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           CLIENT LAYER                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚   Web UI     â”‚  â”‚   CLI Tool   â”‚  â”‚  API Client  â”‚                      â”‚
â”‚  â”‚  (Browser)   â”‚  â”‚  (Terminal)  â”‚  â”‚   (Code)     â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚                 â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          API LAYER (Flask)                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Routes                    Controllers               Middleware       â”‚ â”‚
â”‚  â”‚  GET  /                    render_template()       CORS               â”‚ â”‚
â”‚  â”‚  GET  /api/health          health_check()          Error Handler      â”‚ â”‚
â”‚  â”‚  POST /api/generate        generate_tests()        Request Validator  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       BUSINESS LOGIC LAYER                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚   Input Router  â”‚  â”‚  Test Generator â”‚  â”‚  Output Parser  â”‚             â”‚
â”‚  â”‚  detect_type()  â”‚  â”‚  build_tests()  â”‚  â”‚  parse_json()   â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚           â”‚                    â”‚                                            â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚                            â”‚                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      INFRASTRUCTURE LAYER                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  Ollama Client  â”‚  â”‚  Code Parser    â”‚  â”‚  Prompt Builder â”‚             â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚             â”‚
â”‚  â”‚  generate()     â”‚  â”‚  parse_python() â”‚  â”‚  build_prompt() â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚           â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         LLM LAYER (Local)                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                                       â”‚ â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚ â”‚
â”‚  â”‚    â”‚   Ollama      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Llama 3.2    â”‚                      â”‚ â”‚
â”‚  â”‚    â”‚   Server      â”‚          â”‚    Model      â”‚                      â”‚ â”‚
â”‚  â”‚    â”‚   :11434      â”‚          â”‚               â”‚                      â”‚ â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚ â”‚
â”‚  â”‚                                                                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
Project1-LocalTestCaseGenerator/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                 # Project documentation
â”œâ”€â”€ ğŸ“„ requirements.txt          # Python dependencies
â”œâ”€â”€ ğŸ“„ SETUP_GUIDE.md           # Detailed setup instructions
â”œâ”€â”€ ğŸ“„ DEPLOYMENT.md            # Production deployment guide
â”œâ”€â”€ ğŸ“„ BLAST.md                 # B.L.A.S.T. protocol documentation
â”œâ”€â”€ ğŸ“„ LICENSE                  # MIT License
â”‚
â”œâ”€â”€ ğŸš€ Quick Start Scripts
â”‚   â”œâ”€â”€ START.bat               # One-click Windows start
â”‚   â”œâ”€â”€ start_server.bat        # Server starter
â”‚   â”œâ”€â”€ start_background.vbs    # Background mode (no window)
â”‚   â””â”€â”€ setup_autostart.bat     # Windows boot setup
â”‚
â”œâ”€â”€ ğŸ“¦ Main Package (blast_testgen/)
â”‚   â”œâ”€â”€ web_app.py              # Flask web application
â”‚   â”œâ”€â”€ ollama_client.py        # Ollama LLM client
â”‚   â”œâ”€â”€ orchestrator.py         # Business logic orchestrator
â”‚   â”œâ”€â”€ code_parser.py          # Python code analyzer
â”‚   â”œâ”€â”€ prompts.py              # LLM prompt templates
â”‚   â”œâ”€â”€ cli.py                  # Command-line interface
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ¨ static/              # CSS, JS assets
â”‚   â”‚   â”œâ”€â”€ style.css
â”‚   â”‚   â””â”€â”€ chat.js
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ–¼ï¸ templates/           # HTML templates
â”‚       â””â”€â”€ chat.html
â”‚
â”œâ”€â”€ ğŸ› ï¸ Tools (tools/)
â”‚   â”œâ”€â”€ verify_ollama.py        # Ollama connection checker
â”‚   â”œâ”€â”€ generate_tests.py       # Standalone test generator
â”‚   â””â”€â”€ validate_code.py        # Code validation utility
â”‚
â”œâ”€â”€ ğŸ“‹ Architecture (architecture/)
â”‚   â”œâ”€â”€ SOP-001-TestGeneration.md
â”‚   â”œâ”€â”€ SOP-002-CodeValidation.md
â”‚   â””â”€â”€ SOP-003-OllamaIntegration.md
â”‚
â”œâ”€â”€ âš›ï¸ Frontend (frontend/)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/         # React components
â”‚   â”‚   â”œâ”€â”€ pages/              # Page components
â”‚   â”‚   â””â”€â”€ services/           # API services
â”‚   â””â”€â”€ public/
â”‚
â”œâ”€â”€ ğŸ§ª Tests (tests/)           # Sample test files
â”œâ”€â”€ ğŸ”§ Configs
â”‚   â”œâ”€â”€ deploy.py               # Production server
â”‚   â”œâ”€â”€ run_web.py              # Development server
â”‚   â””â”€â”€ run.py                  # Simple runner
â”‚
â””â”€â”€ ğŸ“ .tmp/                    # Temporary files
```

---

## ğŸ”§ Configuration

### Custom Port
```powershell
# Run on port 8080
python deploy.py --port 8080
```

### Network Access
```powershell
# Allow access from other devices
python deploy.py --host 0.0.0.0
```

### Change Model
Edit `blast_testgen/ollama_client.py`:
```python
DEFAULT_MODEL = "gemma3:1b"  # Lighter/faster model
```

---

## ğŸ› Troubleshooting

| Issue | Solution |
|-------|----------|
| `Ollama not available` | Run `ollama serve` |
| `Module not found` | Run `pip install -r requirements.txt` |
| `Port 5000 in use` | Kill process or use different port |
| `Model not found` | Run `ollama pull llama3.2` |

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](Project1-LocalTestCaseGenerator/LICENSE) file for details.

---

<p align="center">
  <b>Made with â¤ï¸ using Local AI</b><br>
  <sub>Keep your code private. Test smarter. ğŸš€</sub>
</p>

---

## ğŸ“ Support

- ğŸ“§ **Issues:** [GitHub Issues](https://github.com/Qais7744/Local-Testcase-Generation-using-Ollama-Kimi/issues)
- ğŸ“– **Documentation:** Check `Project1-LocalTestCaseGenerator/SETUP_GUIDE.md`
