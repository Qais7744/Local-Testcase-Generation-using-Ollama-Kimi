# ğŸš€ Project1 - Local Test Case Generator (Ollama + Llama 3.2)

> **File:** `README.md` | **Project:** Local TestCase Generator via Ollama

A **local LLM-powered** test case generator using **Ollama** and **Llama 3.2**. Generate comprehensive test cases from your Python code or feature descriptions without sending data to external APIs. Your code stays private! ğŸ”’

---

## ğŸ“‹ Table of Contents
- [Prerequisites](#-prerequisites)
- [Installation](#-installation)
- [How to Run (Start Server)](#-how-to-run-start-server)
- [How to Stop (Kill Server)](#-how-to-stop-kill-server)
- [Usage](#-usage)
- [API Examples](#-api-examples)
- [Project Structure](#-project-structure)
- [Troubleshooting](#-troubleshooting)

---

## âœ… Prerequisites

Before running this project, ensure you have:

| Requirement | Version | Check Command |
|------------|---------|---------------|
| Python | 3.8+ | `python --version` |
| Ollama | Latest | [Download from ollama.com](https://ollama.com) |
| Llama 3.2 Model | latest | `ollama pull llama3.2` |

### Verify Ollama is Running
```powershell
# Check if Ollama server is running
python -c "import requests; print(requests.get('http://localhost:11434/api/tags').status_code)"
# Expected output: 200
```

---

## ğŸ“¦ Installation

### Step 1: Navigate to Project Directory
```powershell
cd Project1-LocalTestCaseGenerator
```

### Step 2: Install Dependencies
```powershell
pip install -r requirements.txt
```

### Step 3: Pull Required Model (One-time)
```powershell
ollama pull llama3.2
```

---

## â–¶ï¸ How to Run (Start Server)

### Method 1: Using Batch File (Windows - Recommended)
```powershell
.\START.bat
```
This will:
1. âœ… Check if Ollama is running
2. âœ… Install dependencies if missing
3. âœ… Start Flask server on `http://localhost:5000`

### Method 2: Manual Start
```powershell
# Terminal 1 - Start Ollama (if not running)
ollama serve

# Terminal 2 - Start Flask Server
python deploy.py --host 127.0.0.1 --port 5000
```

### Method 3: Development Mode (Auto-reload)
```powershell
python run_web.py
```

### Verify Server is Running
Open browser and go to: **http://localhost:5000**

Or use curl/PowerShell:
```powershell
python -c "import requests; print(requests.get('http://127.0.0.1:5000/api/health').json())"
```

---

## â¹ï¸ How to Stop (Kill Server)

### Method 1: Terminal Mein (Recommended)
Jis terminal mein server chal raha hai, wahan press karo:
```
Ctrl + C
```

### Method 2: PowerShell Se (Port 5000 Band Karo)
```powershell
# Find and kill process on port 5000
$port = 5000
$proc = Get-NetTCPConnection -LocalPort $port -ErrorAction SilentlyContinue | Select-Object -ExpandProperty OwningProcess
if ($proc) { taskkill /F /PID $proc }
```

### Method 3: Task Manager Se
1. `Ctrl + Shift + Esc` dabao
2. "Details" tab pe jao
3. `python.exe` dhoondo
4. Right click â†’ "End Task"

### Method 4: Command Prompt Se
```cmd
# Find PID using port 5000
netstat -ano | findstr :5000

# Kill using PID (replace 1234 with actual PID)
taskkill /F /PID 1234
```

---

## ğŸ“ Usage

### Web Interface
1. Browser khol: http://localhost:5000
2. Input type select karo:
   - ğŸ **Python Code** - Function ya class paste karo
   - ğŸ“ **Feature Description** - Plain text mein feature likho
   - ğŸŒ **Website URL** - Example: `google.com`
3. "Generate" button dabao
4. Output dekho:
   - ğŸ“‹ Manual Test Cases
   - ğŸ§ª pytest Automation Code

---

## ğŸ”Œ API Examples

### Health Check
```powershell
python -c "
import requests
r = requests.get('http://127.0.0.1:5000/api/health')
print(r.json())
"
```

### Generate Tests from Python Code
```powershell
python -c "
import requests
import json

payload = {
    'code': '''def login(username, password):
    if not username or not password:
        raise ValueError(\"Required\")
    return {\"token\": \"abc123\"}'''
}

r = requests.post('http://127.0.0.1:5000/api/generate', json=payload)
result = r.json()
print('Manual Tests:', result.get('manual_tests'))
print('Pytest Code:', result.get('pytest_code'))
"
```

### Generate Tests from Feature Description
```powershell
python -c "
import requests

payload = {
    'code': 'Registration page with email, password, confirm password fields'
}

r = requests.post('http://127.0.0.1:5000/api/generate', json=payload)
print(r.json())
"
```

### Generate Tests from Website URL
```powershell
python -c "
import requests

payload = {
    'code': 'app.vwo.com'
}

r = requests.post('http://127.0.0.1:5000/api/generate', json=payload)
print(r.json())
"
```

---

## ğŸ“ Project Structure

```
Project1-LocalTestCaseGenerator/
â”‚
â”œâ”€â”€ ğŸ“„ README.md              # This file
â”œâ”€â”€ ğŸ“„ requirements.txt       # Python dependencies
â”œâ”€â”€ ğŸ“„ START.bat             # One-click server start (Windows)
â”‚
â”œâ”€â”€ ğŸ“ blast_testgen/        # Main Python package
â”‚   â”œâ”€â”€ ğŸ“ static/           # CSS, JS files
â”‚   â”‚   â”œâ”€â”€ style.css
â”‚   â”‚   â””â”€â”€ chat.js
â”‚   â”œâ”€â”€ ğŸ“ templates/        # HTML templates
â”‚   â”‚   â””â”€â”€ chat.html
â”‚   â”œâ”€â”€ cli.py              # Command-line interface
â”‚   â”œâ”€â”€ web_app.py          # Flask web server
â”‚   â”œâ”€â”€ ollama_client.py    # Ollama API client
â”‚   â”œâ”€â”€ orchestrator.py     # Business logic
â”‚   â”œâ”€â”€ code_parser.py      # Python code analysis
â”‚   â””â”€â”€ prompts.py          # LLM prompt templates
â”‚
â”œâ”€â”€ ğŸ“ tools/                # Utility scripts
â”‚   â”œâ”€â”€ verify_ollama.py    # Connection checker
â”‚   â”œâ”€â”€ generate_tests.py   # Standalone generator
â”‚   â””â”€â”€ validate_code.py    # Code validator
â”‚
â”œâ”€â”€ ğŸ“ architecture/         # SOP documentation
â”‚   â”œâ”€â”€ SOP-001-TestGeneration.md
â”‚   â”œâ”€â”€ SOP-002-CodeValidation.md
â”‚   â””â”€â”€ SOP-003-OllamaIntegration.md
â”‚
â””â”€â”€ ğŸ“ tests/                # Sample test files
```

---

## ğŸ”§ Troubleshooting

| Issue | Solution |
|-------|----------|
| "Ollama not running" | Run `ollama serve` in terminal |
| "Module not found" | Run `pip install -r requirements.txt` |
| "Port 5000 already in use" | Kill existing server: `taskkill /F /IM python.exe` |
| "Request timed out" | Use shorter input or simpler code |
| "Model not found" | Run `ollama pull llama3.2` |
| Slow generation | Input is too complex, try shorter code |

---

## ğŸ¤ Contributing

This project follows the **B.L.A.S.T.** protocol:
- **B** - Blueprint (Planning)
- **L** - Link (Connectivity)
- **A** - Architect (3-layer build)
- **S** - Stylize (Refinement)
- **T** - Trigger (Deployment)

---

## ğŸ“„ License

MIT License - Feel free to use and modify!

---

**Made with â¤ï¸ using Local AI (Ollama + Llama 3.2)**
